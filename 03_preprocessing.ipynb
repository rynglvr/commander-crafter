{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f7caa56-96bd-4235-809d-82e653303786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÉè MTG Commander Recommendation System - Step 3\n",
      "üîß Data Preprocessing and Feature Engineering\n",
      "============================================================\n",
      "‚úÖ NLTK data downloaded\n",
      "\n",
      "1Ô∏è‚É£ LOADING PREPROCESSED DATA...\n",
      "‚úÖ Loaded joined data: 83,325 rows, 17 columns\n",
      "‚úÖ Loaded full creatures data: 15,545 creatures\n",
      "\n",
      "2Ô∏è‚É£ DATA CLEANING AND VALIDATION...\n",
      "üßπ Cleaning data...\n",
      "Removed 415 rows with missing critical data\n",
      "‚úÖ Cleaned data: 82,910 valid recommendations\n",
      "\n",
      "3Ô∏è‚É£ VALIDATING COLOR IDENTITY RULES...\n",
      "Color identity compliance: 82,910/82,910 (100.0%)\n",
      "‚úÖ Training data: 82,910 valid recommendations\n",
      "\n",
      "4Ô∏è‚É£ PREPROCESSING ORACLE TEXT...\n",
      "üßπ Cleaning oracle text...\n",
      "‚úÖ Oracle text cleaned: 82,910 recommendations with valid text\n",
      "\n",
      "Sample cleaned oracle text:\n",
      "  1. flying ward whenever another nontoken dragon you control enters create a token that s a copy of it e...\n",
      "  2. flying when tiamat enters if you cast it search your library for up to five dragon cards not named t...\n",
      "  3. flying trample whenever a dragon you control attacks it gains double strike until eot...\n",
      "\n",
      "5Ô∏è‚É£ PREPROCESSING POWER/TOUGHNESS AND PRICES...\n",
      "Power range: -1 to 16\n",
      "Toughness range: 0 to 20\n",
      "Commander price range: $0.02 to $132.68\n",
      "Recommended creature price range: $0.01 to $204.28\n",
      "\n",
      "6Ô∏è‚É£ CREATING ORACLE TEXT EMBEDDINGS...\n",
      "üìù Creating TF-IDF vectors...\n",
      "‚úÖ TF-IDF matrix: 82,910 documents √ó 1,000 features\n",
      "Sample TF-IDF features: ['10', 'abilities', 'abilities artifacts', 'ability', 'ability creature', 'ability permanent', 'ability triggers', 'able', 'activate', 'activate abilities']\n",
      "\n",
      "7Ô∏è‚É£ ANALYZING COMMANDER-SPECIFIC PATTERNS...\n",
      "üîç Analyzing patterns for all commanders...\n",
      "‚úÖ Analyzed patterns for 1,918 commanders\n",
      "\n",
      "Example - The Ur-Dragon:\n",
      "  Total recommendations: 62\n",
      "  Average synergy: 0.30%\n",
      "  Top keywords: [('Flying', 52), ('Haste', 8), ('Trample', 6), ('Treasure', 5), ('Ward', 3)]\n",
      "  Top secondary types: [('Dragon', 54), ('Elder', 9), ('Shaman', 5), ('Spirit', 3), ('Human', 3)]\n",
      "  Average recommended price: $9.47\n",
      "\n",
      "8Ô∏è‚É£ CREATING TRAINING FEATURES...\n",
      "‚úÖ Created features for 82,910 recommendations\n",
      "\n",
      "9Ô∏è‚É£ SAVING PROCESSED DATA...\n",
      "‚úÖ Saved training_features.csv\n",
      "‚úÖ Saved TF-IDF vectorizer\n",
      "‚úÖ Saved commander patterns\n",
      "\n",
      "üîç Verifying parsing results:\n",
      "\n",
      "Creature: Wyluli Wolf\n",
      "  Color Identity: [G] ‚Üí ['G']\n",
      "  Keywords: [] ‚Üí []\n",
      "  Secondary Types: [Wolf] ‚Üí ['Wolf']\n",
      "\n",
      "Creature: Palinchron\n",
      "  Color Identity: [U] ‚Üí ['U']\n",
      "  Keywords: [Flying] ‚Üí ['Flying']\n",
      "  Secondary Types: [Illusion] ‚Üí ['Illusion']\n",
      "\n",
      "Creature: Wei Strike Force\n",
      "  Color Identity: [B] ‚Üí ['B']\n",
      "  Keywords: [Horsemanship] ‚Üí ['Horsemanship']\n",
      "  Secondary Types: [Human, Soldier] ‚Üí ['Human', 'Soldier']\n",
      "\n",
      "‚úÖ Saved processed creatures data\n",
      "\n",
      "üîü SUMMARY AND NEXT STEPS...\n",
      "============================================================\n",
      "‚úÖ COMPLETED:\n",
      "  ‚Ä¢ Cleaned and validated 82,910 recommendations\n",
      "  ‚Ä¢ Created TF-IDF embeddings (1,000 features)\n",
      "  ‚Ä¢ Analyzed 1,918 commander patterns\n",
      "  ‚Ä¢ Preprocessed oracle text, power/toughness, and prices\n",
      "\n",
      "üìä DATA SUMMARY:\n",
      "  ‚Ä¢ Training examples: 82,910\n",
      "  ‚Ä¢ TF-IDF vocabulary: 1,000 terms\n",
      "  ‚Ä¢ Total creatures in database: 15,545\n",
      "  ‚Ä¢ Average synergy score: 0.283\n",
      "  ‚Ä¢ Average recommended creature price: $3.00\n",
      "  ‚Ä¢ Median recommended creature price: $0.50\n",
      "\n",
      "üöÄ READY FOR STEP 4:\n",
      "  ‚Ä¢ Build TensorFlow similarity model\n",
      "  ‚Ä¢ Train on oracle text embeddings\n",
      "  ‚Ä¢ Implement power/toughness weighting\n",
      "  ‚Ä¢ Include price-based features\n",
      "  ‚Ä¢ Create recommendation pipeline\n",
      "\n",
      "üíæ FILES CREATED:\n",
      "  ‚Ä¢ data/processed/training_features.csv\n",
      "  ‚Ä¢ data/processed/tfidf_vectorizer.pkl\n",
      "  ‚Ä¢ data/processed/commander_patterns.pkl\n",
      "  ‚Ä¢ data/processed/creatures_processed.csv\n",
      "\n",
      "üìã Save this notebook as '03_preprocessing.ipynb'\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# MTG Commander Recommendation System - Step 3: Data Preprocessing and Feature Engineering\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import ast\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üÉè MTG Commander Recommendation System - Step 3\")\n",
    "print(\"üîß Data Preprocessing and Feature Engineering\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    print(\"‚úÖ NLTK data downloaded\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è NLTK download failed - proceeding without stopwords\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. LOAD PREPROCESSED DATA\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ LOADING PREPROCESSED DATA...\")\n",
    "\n",
    "# Load the joined data from Step 2\n",
    "try:\n",
    "    df = pd.read_csv('data/processed/recommendations_with_features.csv')\n",
    "    print(f\"‚úÖ Loaded joined data: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Could not find recommendations_with_features.csv\")\n",
    "    print(\"Please run Step 2 (data exploration) first to create this file\")\n",
    "    raise\n",
    "\n",
    "# Load original creatures data for the full candidate pool\n",
    "creatures_df = pd.read_csv('data/raw/all_creatures_clean.csv')\n",
    "print(f\"‚úÖ Loaded full creatures data: {creatures_df.shape[0]:,} creatures\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. DATA CLEANING AND VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ DATA CLEANING AND VALIDATION...\")\n",
    "\n",
    "# Remove rows with missing critical data\n",
    "print(\"üßπ Cleaning data...\")\n",
    "initial_count = len(df)\n",
    "\n",
    "# Keep only rows with valid joins\n",
    "df_clean = df.dropna(subset=['oracle_text', 'color_identity_commander', 'color_identity_recommended'])\n",
    "print(f\"Removed {initial_count - len(df_clean):,} rows with missing critical data\")\n",
    "\n",
    "# Updated parse functions for new format\n",
    "def safe_parse_list(val):\n",
    "    \"\"\"Safely parse string representation of list - Updated for new unquoted format\"\"\"\n",
    "    try:\n",
    "        if pd.isna(val) or val == '[]' or val == '':\n",
    "            return []\n",
    "        if isinstance(val, str):\n",
    "            # Remove brackets and any extra spaces\n",
    "            val = val.strip()\n",
    "            if val.startswith('[') and val.endswith(']'):\n",
    "                val = val[1:-1]  # Remove brackets\n",
    "            if not val:\n",
    "                return []\n",
    "            # Split by comma and clean up spaces, removing empty strings\n",
    "            return [item.strip() for item in val.split(',') if item.strip()]\n",
    "        return val if isinstance(val, list) else []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Parse all list fields with updated parser\n",
    "df_clean['commander_colors'] = df_clean['color_identity_commander'].apply(safe_parse_list)\n",
    "df_clean['recommended_colors'] = df_clean['color_identity_recommended'].apply(safe_parse_list)\n",
    "df_clean['keywords_list'] = df_clean['keywords'].apply(safe_parse_list)\n",
    "\n",
    "# Parse secondary types - Now using array format\n",
    "df_clean['secondary_types_list'] = df_clean['secondary_type'].apply(safe_parse_list)\n",
    "\n",
    "print(f\"‚úÖ Cleaned data: {len(df_clean):,} valid recommendations\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. COLOR IDENTITY VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ VALIDATING COLOR IDENTITY RULES...\")\n",
    "\n",
    "def is_valid_color_identity(recommended_colors, commander_colors):\n",
    "    \"\"\"Check if recommended creature colors are subset of commander colors\"\"\"\n",
    "    if not recommended_colors:  # Colorless is always valid\n",
    "        return True\n",
    "    if not commander_colors:  # Colorless commander can only have colorless creatures\n",
    "        return False\n",
    "    return set(recommended_colors).issubset(set(commander_colors))\n",
    "\n",
    "# Validate color identity rules\n",
    "df_clean['color_valid'] = df_clean.apply(\n",
    "    lambda row: is_valid_color_identity(row['recommended_colors'], row['commander_colors']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "valid_count = df_clean['color_valid'].sum()\n",
    "total_count = len(df_clean)\n",
    "print(f\"Color identity compliance: {valid_count:,}/{total_count:,} ({valid_count/total_count*100:.1f}%)\")\n",
    "\n",
    "# Keep only valid recommendations for training\n",
    "df_valid = df_clean[df_clean['color_valid']].copy()\n",
    "print(f\"‚úÖ Training data: {len(df_valid):,} valid recommendations\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. ORACLE TEXT PREPROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ PREPROCESSING ORACLE TEXT...\")\n",
    "\n",
    "def clean_oracle_text(text):\n",
    "    \"\"\"Clean and normalize oracle text for ML processing\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove mana cost symbols (e.g., {2}{R}{G})\n",
    "    text = re.sub(r'\\{[^}]*\\}', ' ', text)\n",
    "    \n",
    "    # Remove reminder text (text in parentheses)\n",
    "    text = re.sub(r'\\([^)]*\\)', ' ', text)\n",
    "    \n",
    "    # Replace common MTG shorthand\n",
    "    replacements = {\n",
    "        'creature': 'creature',\n",
    "        'instant': 'instant',\n",
    "        'sorcery': 'sorcery',\n",
    "        'artifact': 'artifact',\n",
    "        'enchantment': 'enchantment',\n",
    "        'planeswalker': 'planeswalker',\n",
    "        'enters the battlefield': 'etb',\n",
    "        'end of turn': 'eot',\n",
    "        'beginning of': 'beginning',\n",
    "    }\n",
    "    \n",
    "    for old, new in replacements.items():\n",
    "        text = text.replace(old, new)\n",
    "    \n",
    "    # Remove extra whitespace and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Clean oracle text\n",
    "print(\"üßπ Cleaning oracle text...\")\n",
    "df_valid['oracle_text_clean'] = df_valid['oracle_text'].apply(clean_oracle_text)\n",
    "\n",
    "# Remove empty oracle texts\n",
    "df_valid = df_valid[df_valid['oracle_text_clean'] != ''].copy()\n",
    "print(f\"‚úÖ Oracle text cleaned: {len(df_valid):,} recommendations with valid text\")\n",
    "\n",
    "# Sample cleaned oracle text\n",
    "print(\"\\nSample cleaned oracle text:\")\n",
    "for i, text in enumerate(df_valid['oracle_text_clean'].head(3)):\n",
    "    print(f\"  {i+1}. {text[:100]}...\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. POWER/TOUGHNESS AND PRICE PREPROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£ PREPROCESSING POWER/TOUGHNESS AND PRICES...\")\n",
    "\n",
    "def clean_power_toughness(val):\n",
    "    \"\"\"Clean power/toughness values (handle *, X, etc.)\"\"\"\n",
    "    try:\n",
    "        if pd.isna(val) or val in ['*', 'X']:\n",
    "            return 0  # Default for variable P/T\n",
    "        return float(val)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# Clean power/toughness\n",
    "df_valid['power_clean'] = df_valid['power'].apply(clean_power_toughness)\n",
    "df_valid['toughness_clean'] = df_valid['toughness'].apply(clean_power_toughness)\n",
    "\n",
    "print(f\"Power range: {df_valid['power_clean'].min():.0f} to {df_valid['power_clean'].max():.0f}\")\n",
    "print(f\"Toughness range: {df_valid['toughness_clean'].min():.0f} to {df_valid['toughness_clean'].max():.0f}\")\n",
    "\n",
    "# Clean prices (handle missing values)\n",
    "def clean_price(val):\n",
    "    \"\"\"Clean price values - preserve nulls\"\"\"\n",
    "    try:\n",
    "        if pd.isna(val):\n",
    "            return np.nan  # Keep as null instead of 0\n",
    "        return float(val)\n",
    "    except:\n",
    "        return np.nan  # Return null for any conversion errors\n",
    "\n",
    "# Clean commander and recommended creature prices\n",
    "if 'usd_price_commander' in df_valid.columns:\n",
    "    df_valid['commander_price_clean'] = df_valid['usd_price_commander'].apply(clean_price)\n",
    "    print(f\"Commander price range: ${df_valid['commander_price_clean'].min():.2f} to ${df_valid['commander_price_clean'].max():.2f}\")\n",
    "\n",
    "if 'usd_price_recommended' in df_valid.columns:\n",
    "    df_valid['recommended_price_clean'] = df_valid['usd_price_recommended'].apply(clean_price)\n",
    "    print(f\"Recommended creature price range: ${df_valid['recommended_price_clean'].min():.2f} to ${df_valid['recommended_price_clean'].max():.2f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 6. FEATURE ENGINEERING - ORACLE TEXT EMBEDDINGS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n6Ô∏è‚É£ CREATING ORACLE TEXT EMBEDDINGS...\")\n",
    "\n",
    "# Create TF-IDF vectors for oracle text\n",
    "print(\"üìù Creating TF-IDF vectors...\")\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,  # Limit vocabulary size\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),  # Unigrams and bigrams\n",
    "    min_df=2,  # Must appear in at least 2 documents\n",
    "    max_df=0.8  # Ignore terms that appear in >80% of documents\n",
    ")\n",
    "\n",
    "# Fit TF-IDF on all oracle texts\n",
    "oracle_texts = df_valid['oracle_text_clean'].fillna('')\n",
    "tfidf_matrix = tfidf.fit_transform(oracle_texts)\n",
    "\n",
    "print(f\"‚úÖ TF-IDF matrix: {tfidf_matrix.shape[0]:,} documents √ó {tfidf_matrix.shape[1]:,} features\")\n",
    "\n",
    "# Store feature names for later use\n",
    "tfidf_feature_names = tfidf.get_feature_names_out()\n",
    "print(f\"Sample TF-IDF features: {list(tfidf_feature_names[:10])}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. ANALYZE COMMANDER-SPECIFIC PATTERNS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n7Ô∏è‚É£ ANALYZING COMMANDER-SPECIFIC PATTERNS...\")\n",
    "\n",
    "def analyze_commander_patterns(commander_name, df):\n",
    "    \"\"\"Analyze patterns for a specific commander\"\"\"\n",
    "    commander_recs = df[df['commander_name'] == commander_name].copy()\n",
    "    \n",
    "    if len(commander_recs) == 0:\n",
    "        return None\n",
    "    \n",
    "    patterns = {\n",
    "        'commander': commander_name,\n",
    "        'total_recommendations': len(commander_recs),\n",
    "        'avg_synergy': commander_recs['synergy_percentage'].mean(),\n",
    "        'keywords': [],\n",
    "        'secondary_types': [],\n",
    "        'avg_recommended_price': None,\n",
    "        'price_range': None\n",
    "    }\n",
    "    \n",
    "    # Add price analysis if available\n",
    "    if 'recommended_price_clean' in commander_recs.columns:\n",
    "        patterns['avg_recommended_price'] = commander_recs['recommended_price_clean'].mean()\n",
    "        patterns['price_range'] = (\n",
    "            commander_recs['recommended_price_clean'].min(),\n",
    "            commander_recs['recommended_price_clean'].max()\n",
    "        )\n",
    "    \n",
    "    # Analyze keywords\n",
    "    all_keywords = []\n",
    "    for keywords in commander_recs['keywords_list']:\n",
    "        all_keywords.extend(keywords)\n",
    "    \n",
    "    if all_keywords:\n",
    "        keyword_counts = Counter(all_keywords)\n",
    "        patterns['keywords'] = keyword_counts.most_common(10)\n",
    "    \n",
    "    # Analyze secondary types\n",
    "    all_secondary_types = []\n",
    "    for types in commander_recs['secondary_types_list']:\n",
    "        all_secondary_types.extend(types)\n",
    "    \n",
    "    if all_secondary_types:\n",
    "        type_counts = Counter(all_secondary_types)\n",
    "        patterns['secondary_types'] = type_counts.most_common(10)\n",
    "    \n",
    "    return patterns\n",
    "\n",
    "# Analyze patterns for all commanders\n",
    "print(\"üîç Analyzing patterns for all commanders...\")\n",
    "commander_patterns = {}\n",
    "commanders = df_valid['commander_name'].unique()\n",
    "\n",
    "for commander in commanders:\n",
    "    patterns = analyze_commander_patterns(commander, df_valid)\n",
    "    if patterns:\n",
    "        commander_patterns[commander] = patterns\n",
    "\n",
    "print(f\"‚úÖ Analyzed patterns for {len(commander_patterns):,} commanders\")\n",
    "\n",
    "# Show example patterns\n",
    "if commander_patterns:\n",
    "    example_cmd = list(commander_patterns.keys())[0]\n",
    "    example_patterns = commander_patterns[example_cmd]\n",
    "    print(f\"\\nExample - {example_cmd}:\")\n",
    "    print(f\"  Total recommendations: {example_patterns['total_recommendations']}\")\n",
    "    print(f\"  Average synergy: {example_patterns['avg_synergy']:.2f}%\")\n",
    "    if example_patterns['keywords']:\n",
    "        print(f\"  Top keywords: {example_patterns['keywords'][:5]}\")\n",
    "    if example_patterns['secondary_types']:\n",
    "        print(f\"  Top secondary types: {example_patterns['secondary_types'][:5]}\")\n",
    "    if example_patterns['avg_recommended_price'] is not None:\n",
    "        print(f\"  Average recommended price: ${example_patterns['avg_recommended_price']:.2f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 8. CREATE TRAINING FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n8Ô∏è‚É£ CREATING TRAINING FEATURES...\")\n",
    "\n",
    "# Create feature matrix for each recommendation\n",
    "feature_data = []\n",
    "\n",
    "for idx, row in df_valid.iterrows():\n",
    "    commander = row['commander_name']\n",
    "    patterns = commander_patterns.get(commander, {})\n",
    "    \n",
    "    # Basic features\n",
    "    features = {\n",
    "        'commander': commander,\n",
    "        'recommended_creature': row['recommended_creature_name'],\n",
    "        'synergy_score': row['synergy_percentage'],\n",
    "        'power': row['power_clean'],\n",
    "        'toughness': row['toughness_clean'],\n",
    "        'oracle_text_clean': row['oracle_text_clean'],\n",
    "        'keywords': row['keywords_list'],\n",
    "        'secondary_types': row['secondary_types_list']\n",
    "    }\n",
    "    \n",
    "    # Add price features if available\n",
    "    if 'commander_price_clean' in row:\n",
    "        features['commander_price'] = row['commander_price_clean']\n",
    "    if 'recommended_price_clean' in row:\n",
    "        features['recommended_price'] = row['recommended_price_clean']\n",
    "    \n",
    "    feature_data.append(features)\n",
    "\n",
    "# Create features DataFrame\n",
    "features_df = pd.DataFrame(feature_data)\n",
    "print(f\"‚úÖ Created features for {len(features_df):,} recommendations\")\n",
    "\n",
    "# =============================================================================\n",
    "# 9. SAVE PROCESSED DATA\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n9Ô∏è‚É£ SAVING PROCESSED DATA...\")\n",
    "\n",
    "# Save the processed training data\n",
    "features_df.to_csv('data/processed/training_features.csv', index=False)\n",
    "print(\"‚úÖ Saved training_features.csv\")\n",
    "\n",
    "# Save TF-IDF vectors (as sparse matrix)\n",
    "import pickle\n",
    "with open('data/processed/tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "print(\"‚úÖ Saved TF-IDF vectorizer\")\n",
    "\n",
    "# Save commander patterns\n",
    "with open('data/processed/commander_patterns.pkl', 'wb') as f:\n",
    "    pickle.dump(commander_patterns, f)\n",
    "print(\"‚úÖ Saved commander patterns\")\n",
    "\n",
    "# Save cleaned full creatures data for candidate generation\n",
    "creatures_clean = creatures_df.copy()\n",
    "creatures_clean['oracle_text_clean'] = creatures_clean['oracle_text'].apply(clean_oracle_text)\n",
    "creatures_clean['power_clean'] = creatures_clean['power'].apply(clean_power_toughness)\n",
    "creatures_clean['toughness_clean'] = creatures_clean['toughness'].apply(clean_power_toughness)\n",
    "\n",
    "# Apply the parsing functions to the original columns\n",
    "creatures_clean['color_identity_parsed'] = creatures_clean['color_identity'].apply(safe_parse_list)\n",
    "creatures_clean['keywords_parsed'] = creatures_clean['keywords'].apply(safe_parse_list)\n",
    "creatures_clean['secondary_types_parsed'] = creatures_clean['secondary_type'].apply(safe_parse_list)\n",
    "\n",
    "# Add price cleaning for creatures\n",
    "if 'usd_price' in creatures_clean.columns:\n",
    "    creatures_clean['price_clean'] = creatures_clean['usd_price'].apply(clean_price)\n",
    "\n",
    "# Debug: Check a few examples to ensure parsing is working correctly\n",
    "print(\"\\nüîç Verifying parsing results:\")\n",
    "sample_idx = creatures_clean[creatures_clean['keywords'].notna()].index[:3]\n",
    "for idx in sample_idx:\n",
    "    print(f\"\\nCreature: {creatures_clean.loc[idx, 'name']}\")\n",
    "    print(f\"  Color Identity: {creatures_clean.loc[idx, 'color_identity']} ‚Üí {creatures_clean.loc[idx, 'color_identity_parsed']}\")\n",
    "    print(f\"  Keywords: {creatures_clean.loc[idx, 'keywords']} ‚Üí {creatures_clean.loc[idx, 'keywords_parsed']}\")\n",
    "    print(f\"  Secondary Types: {creatures_clean.loc[idx, 'secondary_type']} ‚Üí {creatures_clean.loc[idx, 'secondary_types_parsed']}\")\n",
    "\n",
    "creatures_clean.to_csv('data/processed/creatures_processed.csv', index=False)\n",
    "print(\"\\n‚úÖ Saved processed creatures data\")\n",
    "\n",
    "# =============================================================================\n",
    "# 10. SUMMARY AND NEXT STEPS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüîü SUMMARY AND NEXT STEPS...\")\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úÖ COMPLETED:\")\n",
    "print(f\"  ‚Ä¢ Cleaned and validated {len(df_valid):,} recommendations\")\n",
    "print(f\"  ‚Ä¢ Created TF-IDF embeddings ({tfidf_matrix.shape[1]:,} features)\")\n",
    "print(f\"  ‚Ä¢ Analyzed {len(commander_patterns):,} commander patterns\")\n",
    "print(\"  ‚Ä¢ Preprocessed oracle text, power/toughness, and prices\")\n",
    "\n",
    "print(\"\\nüìä DATA SUMMARY:\")\n",
    "print(f\"  ‚Ä¢ Training examples: {len(features_df):,}\")\n",
    "print(f\"  ‚Ä¢ TF-IDF vocabulary: {len(tfidf_feature_names):,} terms\")\n",
    "print(f\"  ‚Ä¢ Total creatures in database: {len(creatures_clean):,}\")\n",
    "print(f\"  ‚Ä¢ Average synergy score: {features_df['synergy_score'].mean():.3f}\")\n",
    "\n",
    "if 'recommended_price' in features_df.columns:\n",
    "    print(f\"  ‚Ä¢ Average recommended creature price: ${features_df['recommended_price'].mean():.2f}\")\n",
    "    print(f\"  ‚Ä¢ Median recommended creature price: ${features_df['recommended_price'].median():.2f}\")\n",
    "\n",
    "print(\"\\nüöÄ READY FOR STEP 4:\")\n",
    "print(\"  ‚Ä¢ Build TensorFlow similarity model\")\n",
    "print(\"  ‚Ä¢ Train on oracle text embeddings\")\n",
    "print(\"  ‚Ä¢ Implement power/toughness weighting\")\n",
    "print(\"  ‚Ä¢ Include price-based features\")\n",
    "print(\"  ‚Ä¢ Create recommendation pipeline\")\n",
    "\n",
    "print(\"\\nüíæ FILES CREATED:\")\n",
    "print(\"  ‚Ä¢ data/processed/training_features.csv\")\n",
    "print(\"  ‚Ä¢ data/processed/tfidf_vectorizer.pkl\")\n",
    "print(\"  ‚Ä¢ data/processed/commander_patterns.pkl\")\n",
    "print(\"  ‚Ä¢ data/processed/creatures_processed.csv\")\n",
    "\n",
    "print(\"\\nüìã Save this notebook as '03_preprocessing.ipynb'\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49a510-aa41-4dbc-a45a-6a22d0004dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
